{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Accuracy: Pitfalls and Edge Cases\n",
    "\n",
    "This notebook describes OpenDP's accuracy calculations, and ways in which an analyst might be tripped up by them.\n",
    "\n",
    "### Overview\n",
    "\n",
    "#### Accuracy vs. Confidence Intervals\n",
    "\n",
    "Each privatizing mechanism (e.g. Laplace, Gaussian) in OpenDP has an associated accuracy that is a function of alpha and\n",
    "either sigma or accuracy. Imagine you have data $D$, and you want, for some function $\\phi$ to return $\\phi(D)$ in a\n",
    "differentially private way -- we will call this value $\\phi_{dp}(D)$. An $\\alpha$-level accuracy guarantee $a$ promises\n",
    "that, over infinite runs of the privatizing mechanism on the data in question,\n",
    "$$ \\phi(D) \\in [\\phi_{dp}(D) - a, \\phi_{dp}(D) + a] $$\n",
    "with probability $1 - \\alpha$.\n",
    "\n",
    "This looks very much like the traditional confidence interval, but it is important to note a major difference. In a\n",
    "canonical confidence interval, the uncertainty being represented is due to sampling error -- that is, how often will it\n",
    "be the case that $\\phi(P)$ (the value of $\\phi$ on the underlying population) is within some range of the realized\n",
    "$\\phi(D)$.\n",
    "\n",
    "In OpenDP (and differentially private data analysis generally), there is an extra layer of uncertainty due to the noise\n",
    "added to $\\phi(D)$ to produce $\\phi_{dp}(D)$. OpenDP's accuracy metrics deal only with the uncertainty of $\\phi_{dp}(D)$\n",
    " relative to $\\phi(D)$ and not the uncertainty of $\\phi(D)$ relative to $\\phi(P)$.\n",
    "\n",
    "#### What is $D$?\n",
    "\n",
    "OpenDP allows for analysis of data with an unknown number of rows by resizing the data to ensure consistency with an\n",
    "estimated size\n",
    "(see the [unknown dataset size notebook](https://github.com/opendp/opendp/blob/main/python/example/unknown_dataset_size.ipynb)\n",
    "for more details). Accuracy guarantees are always relative to the resized data $\\tilde{D}$, not the data of unknown size.\n",
    "\n",
    "#### Synopsis\n",
    "\n",
    "Let's say an analyst releases $\\phi_{dp}(D)$ and gets an accuracy guarantee of $a$ at accuracy-level $\\alpha$. $D$\n",
    "is a dataset of unknown size drawn from population $P$ and will be resized to $\\tilde{D}$. This suggests that over\n",
    "infinite runs of this procedure,\n",
    "\n",
    "- $\\phi_{dp}(D) \\in [\\phi(\\tilde{D}) - a, \\phi(\\tilde{D}) + a]$ with probability $1 - \\alpha$\n",
    "- It is likely that $\\phi_{dp}(D) \\in [\\phi(D) - a, \\phi(D) + a]$ with probability $\\approx 1 - \\alpha$, though we\n",
    "cannot make any guarantee. For many cases (e.g. resizing the data based on $n$ obtained from a differentially private\n",
    "count and reasonable bounds on the data elements), this is likely to be approximately true. In the next section, we will\n",
    "explore some examples of cases where this statement holds to varying extents.\n",
    "\n",
    "- We cannot directly make statements about the relationship uncertainty of $\\phi_{dp}(D)$ relative to $\\phi(P)$.\n",
    "\n",
    "### Accuracy Guarantees In Practice\n",
    "\n",
    "We now move to some empirical evaluations of how well our accuracy guarantees translate from $\\phi(\\tilde{D})$ to\n",
    "$\\phi(D)$. We first consider the case where we actually know the size of the underlying data and are able to set\n",
    "plausible lower/upper bounds on `age`.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/PUMS_california_demographics_1000/data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/4s/j9k238qs6wbcv8s2psqnyzh40000gp/T/ipykernel_75404/119168807.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[0mdata_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'.'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'data'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'PUMS_california_demographics_1000'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'data.csv'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[0mvar_names\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m\"age\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"sex\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"educ\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"race\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"income\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"married\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"pid\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 18\u001B[0;31m \u001B[0mD\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnames\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mvar_names\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     19\u001B[0m \u001B[0mage\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mD\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mage\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[0mD_mean_age\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mage\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/IdeaProjects/opendp/venv/lib/python3.8/site-packages/pandas/util/_decorators.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    309\u001B[0m                     \u001B[0mstacklevel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstacklevel\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    310\u001B[0m                 )\n\u001B[0;32m--> 311\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    312\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    313\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/IdeaProjects/opendp/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001B[0m in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[1;32m    584\u001B[0m     \u001B[0mkwds\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkwds_defaults\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    585\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 586\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    587\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    588\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/IdeaProjects/opendp/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001B[0m in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    480\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    481\u001B[0m     \u001B[0;31m# Create the parser.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 482\u001B[0;31m     \u001B[0mparser\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    483\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    484\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/IdeaProjects/opendp/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m    809\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"has_index_names\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"has_index_names\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    810\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 811\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    812\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    813\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/IdeaProjects/opendp/venv/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[0;34m(self, engine)\u001B[0m\n\u001B[1;32m   1038\u001B[0m             )\n\u001B[1;32m   1039\u001B[0m         \u001B[0;31m# error: Too many arguments for \"ParserBase\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1040\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mmapping\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# type: ignore[call-arg]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1041\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1042\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_failover_to_python\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/IdeaProjects/opendp/venv/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, src, **kwds)\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     50\u001B[0m         \u001B[0;31m# open handles\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 51\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_open_handles\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     52\u001B[0m         \u001B[0;32massert\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhandles\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/IdeaProjects/opendp/venv/lib/python3.8/site-packages/pandas/io/parsers/base_parser.py\u001B[0m in \u001B[0;36m_open_handles\u001B[0;34m(self, src, kwds)\u001B[0m\n\u001B[1;32m    220\u001B[0m         \u001B[0mLet\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mreaders\u001B[0m \u001B[0mopen\u001B[0m \u001B[0mIOHandles\u001B[0m \u001B[0mafter\u001B[0m \u001B[0mthey\u001B[0m \u001B[0mare\u001B[0m \u001B[0mdone\u001B[0m \u001B[0;32mwith\u001B[0m \u001B[0mtheir\u001B[0m \u001B[0mpotential\u001B[0m \u001B[0mraises\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    221\u001B[0m         \"\"\"\n\u001B[0;32m--> 222\u001B[0;31m         self.handles = get_handle(\n\u001B[0m\u001B[1;32m    223\u001B[0m             \u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    224\u001B[0m             \u001B[0;34m\"r\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/IdeaProjects/opendp/venv/lib/python3.8/site-packages/pandas/io/common.py\u001B[0m in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    700\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mioargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mencoding\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;34m\"b\"\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mioargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    701\u001B[0m             \u001B[0;31m# Encoding\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 702\u001B[0;31m             handle = open(\n\u001B[0m\u001B[1;32m    703\u001B[0m                 \u001B[0mhandle\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    704\u001B[0m                 \u001B[0mioargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: './data/PUMS_california_demographics_1000/data.csv'"
     ]
    }
   ],
   "source": [
    "# load libraries\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from opendp.accuracy import laplacian_scale_to_accuracy\n",
    "from opendp.meas import make_base_laplace\n",
    "from opendp.mod import enable_features, binary_search, binary_search_param\n",
    "from opendp.trans import make_split_dataframe, make_cast_default, make_clamp, make_bounded_resize, \\\n",
    "    make_sized_bounded_mean, make_select_column, make_impute_uniform_float, make_cast_inherent\n",
    "\n",
    "enable_features(\"contrib\")\n",
    "enable_features(\"floating-point\")\n",
    "\n",
    "data_path = os.path.join('.', 'data', 'PUMS_california_demographics_1000', 'data.csv')\n",
    "var_names = [\"age\", \"sex\", \"educ\", \"race\", \"income\", \"married\", \"pid\"]\n",
    "D = pd.read_csv(data_path, names=var_names)\n",
    "age = D.age\n",
    "D_mean_age = np.mean(age)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# establish extra information for this simulation\n",
    "age_bounds = (0., 100.)\n",
    "data_size = 1_000\n",
    "n_sims = 1_000\n",
    "epsilon = 1.\n",
    "alpha = 0.05\n",
    "releases = []\n",
    "\n",
    "D_tilde = np.clip(D.age, age_bounds[0], age_bounds[1])\n",
    "D_tilde_mean_age = np.mean(D_tilde)\n",
    "\n",
    "preprocessor = (\n",
    "    # Convert data into a dataframe of string columns\n",
    "    make_split_dataframe(separator=\",\", col_names=var_names) >>\n",
    "\n",
    "    # Selects a column of df, Vec<str>\n",
    "    make_select_column(key=\"age\", TOA=str) >>\n",
    "\n",
    "    # Cast the column as Vec<float>, and fill nulls with the default value, 0.\n",
    "    make_cast_default(TIA=str, TOA=float) >>\n",
    "\n",
    "    # Clamp age values\n",
    "    make_clamp(bounds=age_bounds) >>\n",
    "\n",
    "    # Resize the dataset to length `count_release`.\n",
    "    #     If there are fewer than `count_release` rows in the data, fill with a constant of 20.\n",
    "    #     If there are more than `count_release` rows in the data, only keep `count_release` rows\n",
    "    make_bounded_resize(size=data_size, bounds=age_bounds, constant=20.) >>\n",
    "\n",
    "    # Compute the mean\n",
    "    make_sized_bounded_mean(size=data_size, bounds=age_bounds)\n",
    ")\n",
    "scale = binary_search_param(lambda s: preprocessor >> make_base_laplace(s), 1, epsilon)\n",
    "\n",
    "measurement = preprocessor >> make_base_laplace(scale)\n",
    "\n",
    "with open(data_path, 'r') as infile:\n",
    "    data = infile.read()\n",
    "    for index in range(n_sims):\n",
    "        # get DP mean of age\n",
    "        releases.append(\n",
    "            measurement(data)\n",
    "        )\n",
    "accuracy = laplacian_scale_to_accuracy(scale, alpha)\n",
    "print('Accuracy interval (with accuracy value {0}) contains the true mean on D_tilde with probability {1}'.format(\n",
    "    round(accuracy, 4),\n",
    "    np.mean([(D_tilde_mean_age >= val - accuracy) & (D_tilde_mean_age <= val + accuracy) for val in releases])))\n",
    "\n",
    "print('Accuracy interval (with accuracy value {0}) contains the true mean on D with probability {1}'.format(\n",
    "    round(accuracy, 4),\n",
    "    np.mean([(D_mean_age >= val - accuracy) & (D_mean_age <= val + accuracy) for val in releases])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "|This performance is as expected. $D$ and $\\tilde{D}$ are actually the exact same data (the maximum age in the raw data\n",
    " is 93, so our clamp to $[0, 100]$ does not change any values, and we know the correct $n$), so our theoretical\n",
    " guarantees on $\\tilde{D}$ map exactly to gaurantees on $D$.\n",
    "\n",
    "We now move to a scenario that is still realistic, but where the performance does not translate quite as well. In this\n",
    " case, we imagine that the analyst believes the data to be of size 1050 and uses the default imputation within resize\n",
    " so that the extra 50 elements are drawn uniformly from $\\{ 0, 1, ..., 100 \\}$.\n",
    "\n",
    "Note that our diagnostic testing of $\\tilde{D}$ in the code above is not trivial in this case. In the first example, we\n",
    "knew that clamp/resize did not change the underlying data, so we could predict exactly the data on which the DP mean\n",
    " would actually be calculated. This will not be true for the following examples, so we will simulate finding the true\n",
    " underlying mean by releasing an extra DP mean with very high epsilon."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# establish extra information for this simulation\n",
    "data_size = 1050\n",
    "\n",
    "n_sims = 1_000\n",
    "true_D_tilde_mean_ages = []\n",
    "dp_D_tilde_mean_ages = []\n",
    "\n",
    "D_tilde = np.clip(D.age, age_bounds[0], age_bounds[1])\n",
    "D_tilde_mean_age = np.mean(D_tilde)\n",
    "\n",
    "preprocessor = (\n",
    "    # Convert data into a dataframe of string columns\n",
    "    make_split_dataframe(separator=\",\", col_names=var_names) >>\n",
    "\n",
    "    # Selects a column of df, Vec<str>\n",
    "    make_select_column(key=\"age\", TOA=str) >>\n",
    "\n",
    "    # Cast the column as Vec<float>\n",
    "    make_cast_inherent(TIA=str, TOA=float) >>\n",
    "\n",
    "    # TODO: we need to impute missing values sampled from uniform, not a constant (see line 168)\n",
    "    make_impute_uniform_float(bounds=age_bounds) >>\n",
    "\n",
    "    # Clamp age values\n",
    "    make_clamp(bounds=age_bounds) >>\n",
    "\n",
    "    # Resize the dataset to length `data_size`.\n",
    "    #     If there are fewer than `data_size` rows in the data, fill with a constant of 20.\n",
    "    #     If there are more than `data_size` rows in the data, only keep `count_release` rows\n",
    "    make_bounded_resize(size=data_size, bounds=age_bounds, constant=20.) >>\n",
    "\n",
    "    # Compute the mean\n",
    "    make_sized_bounded_mean(size=data_size, bounds=age_bounds)\n",
    ")\n",
    "\n",
    "scale = binary_search_param(lambda s: preprocessor >> make_base_laplace(s), 1, epsilon)\n",
    "\n",
    "measurement = preprocessor >> make_base_laplace(scale)\n",
    "\n",
    "with open(data_path, 'r') as infile:\n",
    "    data = infile.read()\n",
    "    for index in range(n_sims):\n",
    "        # get DP mean of age\n",
    "        releases.append(\n",
    "            measurement(data)\n",
    "        )\n",
    "accuracy = laplacian_scale_to_accuracy(scale, alpha)\n",
    "print('Accuracy interval (with accuracy value {0}) contains the true mean on D_tilde with probability {1}'.format(\n",
    "    round(accuracy, 4),\n",
    "    np.mean([(D_tilde_mean_age >= val - accuracy) & (D_tilde_mean_age <= val + accuracy) for val in releases])))\n",
    "\n",
    "print('Accuracy interval (with accuracy value {0}) contains the true mean on D with probability {1}'.format(\n",
    "    round(accuracy, 4),\n",
    "    np.mean([(D_mean_age >= val - accuracy) & (D_mean_age <= val + accuracy) for val in releases])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The accuracy guarantee still holds on $\\tilde{D}$ (as it should), but we now see much worse performance relative to the\n",
    "true underlying data $D$."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}